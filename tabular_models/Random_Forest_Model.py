import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report

# Load and preprocess tabular data
filename = "/kaggle/input/adwarem/testing.xlsx"
df = pd.read_excel(filename)
df.isnull().values.any()

df.drop(columns=['Hash', 'Category'], axis=1, inplace=True)

# Encode categorical labels
encoder = LabelEncoder()
df['Label'] = encoder.fit_transform(df['Family'])
# Remove the original categorical feature
df.drop(columns = 'Family' ,axis=1, inplace=True)
y = df['Label']  #label
X = df.drop(columns = 'Label', axis=1) #features

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)
# Hyperparameter tuning using GridSearchCV
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt']
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
print("Best Hyperparameters for RF with Highest Accuracy Score:", best_params)
# Make predictions on the test set using the best model
best_model = RandomForestClassifier(**best_params, criterion= 'entropy')
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)
# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)
# Compute other metrics
print("Classification Report:")
print(classification_report(y_test, y_pred))


# Best Hyperparameters for RF with Highest Accuracy Score: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}
# Confusion Matrix:
# [[404   4]
#  [  7 171]]
# Classification Report:
#               precision    recall  f1-score   support

#            0       0.98      0.99      0.99       408
#            1       0.98      0.96      0.97       178

#     accuracy                           0.98       586
#    macro avg       0.98      0.98      0.98       586
# weighted avg       0.98      0.98      0.98       586