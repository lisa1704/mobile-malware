import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.naive_bayes import GaussianNB

filename = "/kaggle/input/adwarem/testing.xlsx"
df = pd.read_excel(filename)

#Check for null values
df.isnull().values.any()

df.drop(columns=['Hash', 'Category'], axis=1, inplace=True)

# Encode categorical labels
encoder = LabelEncoder()
df['Label'] = encoder.fit_transform(df['Family'])
# Remove the original categorical feature
df.drop(columns = 'Family' ,axis=1, inplace=True)
y = df['Label']  #label
X = df.drop(columns = 'Label', axis=1) #features

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)

param_grid = {
    'var_smoothing': np.logspace(0,-9, num=100)
}

grid_search = GridSearchCV(GaussianNB(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
print("Best Hyperparameters for GaussianNB with Highest Accuracy Score:", best_params)

best_model =  GaussianNB(**best_params)
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Compute other metrics
print("Classification Report:")
print(classification_report(y_test, y_pred))


# Best Hyperparameters for GaussianNB with Highest Accuracy Score: {'var_smoothing': 1.232846739442066e-08}
# Confusion Matrix:
# [[392  16]
#  [132  46]]
# Classification Report:
#               precision    recall  f1-score   support

#            0       0.75      0.96      0.84       408
#            1       0.74      0.26      0.38       178

#     accuracy                           0.75       586
#    macro avg       0.75      0.61      0.61       586
# weighted avg       0.75      0.75      0.70       586