import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report

filename = ("testing.xlsx")
df = pd.read_excel(filename)


#Check for null values
df.isnull().values.any()
df.drop(columns=['Hash', 'Category'], axis=1, inplace=True)

#Use one hot encoder for the label
encoder = LabelEncoder()
df['Label'] = encoder.fit_transform(df['Family'])
# Remove the original categorical feature
df.drop(columns = 'Family' ,axis=1, inplace=True)
y = df['Label']  #label
X = df.drop(columns = 'Label', axis=1) #features

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state = 1234)

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [6, 8, 10],
    'min_child_weight': [1, 5, 10],
    'gamma': [0.5, 1, 1.5],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

grid_search = GridSearchCV(xgb.XGBClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
print("Best Hyperparameters with Highest Accuracy Score:", best_params)

best_model =  xgb.XGBClassifier(**best_params)
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Compute other metrics
print("Classification Report:")
print(classification_report(y_test, y_pred))




# Best Hyperparameters with Highest Accuracy Score: {'colsample_bytree': 0.6, 'gamma': 1.5, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 
# 100, 'subsample': 0.8}
# Confusion Matrix:
# [[184   7]
#  [  4  85]]
# Classification Report:
#               precision    recall  f1-score   support

#            0       0.98      0.96      0.97       191
#            1       0.92      0.96      0.94        89

#     accuracy                           0.96       280
#    macro avg       0.95      0.96      0.96       280
# weighted avg       0.96      0.96      0.96       280