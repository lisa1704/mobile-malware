import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc

filename = ("Obfuscated-MalMem2022.csv")
df = pd.read_csv(filename)

#Remove the category value because that tells so much about the label already
df.drop(columns = "Category", axis = 1, inplace=True)
#print(df.d types)

#Check for null values
df.isnull().values.any()

#Use one hot encoder for the label
# Create the encoder:
encoder = LabelEncoder()
# Apply the encoder:
df['Label'] = encoder.fit_transform(df['Class'])
# Remove the original categorical feature
df.drop(columns = 'Class' ,axis=1, inplace=True)


y = df['Label']  #label
X = df.drop(columns = 'Label', axis=1) #features

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.10, random_state = 1234)

param_grid = {
    'n_estimators': [100, 200]
}

# Create a GridSearchCV object
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
print("Best Hyperparameters for RF with Highest Accuracy Score:", best_params)

best_model = RandomForestClassifier(**best_params, criterion= 'entropy')
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

print('Computing ROC Curve...')
fpr, tpr, thresholds= roc_curve(y_test, y_pred)
auc = auc(fpr, tpr)
print("AUC of the RF model is {:.3f}".format(auc))

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Compute other metrics
print("Classification Report:")
print(classification_report(y_test, y_pred))


#Best Hyperparameters for RF with Highest Accuracy Score: {'n_estimators': 100}
#Computing ROC Curve...
#AUC of the RF model witheis 1.000
#Confusion Matrix:
#[[2894    0]
# [   0 2966]]
#Classification Report:
#              precision    recall  f1-score   support

#           0       1.00      1.00      1.00      2894
#           1       1.00      1.00      1.00      2966

#    accuracy                           1.00      5860
#   macro avg       1.00      1.00      1.00      5860
#weighted avg       1.00      1.00      1.00      5860


