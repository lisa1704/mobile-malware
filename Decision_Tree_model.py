import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report

filename = ("Obfuscated-MalMem2022.csv")
df = pd.read_csv(filename)

#Remove the category value because that tells so much about the label already
df.drop(columns = "Category", axis = 1, inplace=True)

#Check for null values
df.isnull().values.any()

#Use one hot encoder for the label
# Create the encoder:
encoder = LabelEncoder()
# Apply the encoder:
df['Label'] = encoder.fit_transform(df['Class'])
# Remove the original categorical feature
df.drop(columns = 'Class' ,axis=1, inplace=True)

y = df['Label']  #label
X = df.drop(columns = 'Label', axis=1) #features

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.10, random_state = 1234)

# Define the parameter grid for GridSearchCV
param_grid = {
    'max_depth': range(1, 50),
    'min_samples_leaf': range(1, 50),
}

# Create a GridSearchCV object
grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Get the best parameters from the grid search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Initialize the DecisionTreeClassifier with the best parameters
best_model = DecisionTreeClassifier(**best_params)
best_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = best_model.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Compute other metrics
print("Classification Report:")
print(classification_report(y_test, y_pred))


#Result
#Best Hyperparameters: {'max_depth': 20, 'min_samples_leaf': 1}
#Confusion Matrix:
#[[2894    0]
# [   0 2966]]
#Classification Report:
#              precision    recall  f1-score   support
#
#           0       1.00      1.00      1.00      2894
#           1       1.00      1.00      1.00      2966

#    accuracy                           1.00      5860
#   macro avg       1.00      1.00      1.00      5860
#weighted avg       1.00      1.00      1.00      5860










